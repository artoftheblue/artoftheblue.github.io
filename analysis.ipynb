{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4306736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import altair as alt\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wordfreq as wf\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import cache\n",
    "\n",
    "print(\"Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf9ecf",
   "metadata": {
    "user_expressions": [
     {
      "expression": "a + b",
      "result": {
       "data": {
        "text/plain": "5"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "{eval}`a + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94474c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, word, _type):\n",
    "        self.word = word\n",
    "        self.type = _type\n",
    "        self.lang = self.eval_lang(self.word)\n",
    "        self.freq = self.eval_freq(self.word, self.lang)\n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_lang(word):\n",
    "        if any(letter in word.lower() for letter in \"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"):\n",
    "            return \"ru\"\n",
    "        return \"en\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_freq(word, language):\n",
    "        return wf.word_frequency(word, language)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.word\n",
    "\n",
    "\n",
    "class Message:\n",
    "    characters_to_remove = r'!@#$%^&*()_+=/?\\|][{}<>;\"~`—–«»'\n",
    "    border_characters = \"'-:\"\n",
    "    replacement_pairs = [\n",
    "        (\"\\\\\", \" \"),\n",
    "        (\"/\", \" \"),\n",
    "        (\"|\", \" \"),\n",
    "        (\".\", \" \"),\n",
    "        (\",\", \" \"),\n",
    "        (\"”\", '\"'),\n",
    "        (\"“\", '\"'),\n",
    "        (\"’\", \"'\"),\n",
    "        (\"‘\", \"'\"),\n",
    "        (\"»\", '\"'),\n",
    "        (\"«\", '\"'),\n",
    "        (\"…\", \"...\")\n",
    "    ]\n",
    "\n",
    "    def __init__(self, id, unixtime, text_entities):\n",
    "        self.id = id\n",
    "        self.time = datetime.datetime.fromtimestamp(int(unixtime))\n",
    "        self.strings = []\n",
    "        self.words = []\n",
    "\n",
    "        self.__process_text(text_entities)\n",
    "    \n",
    "    def __process_text(self, text_entities):\n",
    "        def filtered(string):\n",
    "            string = string.lower()\n",
    "\n",
    "            for pair in Message.replacement_pairs:\n",
    "                string = string.replace(*pair)\n",
    "\n",
    "            for char in Message.characters_to_remove:\n",
    "                string = string.replace(char, '')\n",
    "\n",
    "            return string\n",
    "        \n",
    "        def filtered2(string):\n",
    "            while any(string.startswith(char) for char in Message.border_characters):\n",
    "                string = string[1:]\n",
    "\n",
    "            while any(string.endswith(char) for char in Message.border_characters):\n",
    "                string = string[:-1]\n",
    "            \n",
    "            return string\n",
    "        \n",
    "        for entity in text_entities:\n",
    "            for string in entity[\"text\"].split():\n",
    "                self.strings.append(Word(string, entity[\"type\"]))\n",
    "            \n",
    "            for word in filtered(entity[\"text\"]).split():\n",
    "                word = filtered2(word)\n",
    "\n",
    "                if word == \"\":\n",
    "                    continue\n",
    "\n",
    "                self.words.append(Word(word, entity[\"type\"]))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"[{self.time}] {' '.join(self.strings)}\\n{' '.join(self.words)}\"\n",
    "\n",
    "\n",
    "class Call:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class User:\n",
    "    def __init__(self, id, name):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.messages = []\n",
    "        self.calls = []\n",
    "    \n",
    "    def _add_message(self, json_object):\n",
    "        if \"text_entities\" not in json_object:\n",
    "            json_object[\"text_entities\"] = self.to_json(json_object[\"text\"])\n",
    "        \n",
    "        self.messages.append(Message(json_object[\"id\"], json_object[\"date_unixtime\"], json_object[\"text_entities\"]))\n",
    "    \n",
    "    def _add_call(self, json_object):\n",
    "        self.calls = Call()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(string):\n",
    "        return [{\"text\": string, \"type\": \"plain\"}]\n",
    "\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, *uploaders, user_class=User):\n",
    "        self.id = None\n",
    "        self.me = None\n",
    "        self.you = None\n",
    "\n",
    "        for uploader in uploaders:\n",
    "            if len(uploader.value) != 0:\n",
    "                data = self.__load_data(uploader)\n",
    "                self.__process_messages(user_class, data)\n",
    "\n",
    "    def __load_data(self, uploader):\n",
    "        raw_data = json.loads(uploader.value[list(uploader.value.keys())[0]][\"content\"])\n",
    "        #raw_data = json.loads(uploader.value[0].content.tobytes())\n",
    "\n",
    "        if \"type\" in raw_data and raw_data[\"type\"] != \"personal_chat\":\n",
    "            raise FileNotFoundError(\"File uploaded is not from a personal_chat\")\n",
    "        \n",
    "        if self.id == None:\n",
    "            self.id = str(raw_data[\"id\"])\n",
    "\n",
    "        return raw_data\n",
    "    \n",
    "    def __process_messages(self, user_class, raw_data):\n",
    "        def user(id):\n",
    "            if id.endswith(self.id):\n",
    "                return self.you\n",
    "            return self.me\n",
    "        \n",
    "        if raw_data == None:\n",
    "            raise FileNotFoundError(\"No data loaded\")\n",
    "\n",
    "        for json_object in raw_data[\"messages\"]:\n",
    "            if \"type\" not in json_object or json_object[\"type\"] == \"message\":\n",
    "                id = json_object[\"from_id\"]\n",
    "\n",
    "                if self.me == None or self.you == None:\n",
    "                    if id.endswith(self.id):\n",
    "                        self.you = user_class(self.id, json_object[\"from\"])\n",
    "                    else:\n",
    "                        self.me = user_class(id[4:], json_object[\"from\"])\n",
    "                \n",
    "                user(id)._add_message(json_object)\n",
    "            elif json_object[\"type\"] == \"service\":\n",
    "                pass\n",
    "            else:\n",
    "                print(\"[WARNING] unknown object found\")\n",
    "                display(json_object)\n",
    "\n",
    "\n",
    "class module_WordCounts:\n",
    "    @cache\n",
    "    def __word_counts(self, attribute):        \n",
    "        dictionary = defaultdict(lambda: [0])\n",
    "\n",
    "        for message in self.messages:\n",
    "            for word in getattr(message, attribute): \n",
    "                dictionary[word.word][0] += 1\n",
    "\n",
    "        df = pd.DataFrame(dictionary).transpose().reset_index()\n",
    "        df.columns = [\"word\", \"count\"]\n",
    "        return df\n",
    "\n",
    "    @cache\n",
    "    def word_counts_sorted(self, cleaned=True):\n",
    "        return self.word_counts_alpha(cleaned).sort_values(\"count\", ascending=False)\n",
    "\n",
    "    @cache\n",
    "    def word_counts_alpha(self, cleaned=True):\n",
    "        attribute = \"words\" \n",
    "        if not cleaned:\n",
    "            attribute = \"strings\"\n",
    "            \n",
    "        return self.__word_counts(attribute).sort_index()\n",
    "    \n",
    "    @cache\n",
    "    def unique_words(self, cleaned=True):\n",
    "        return self.word_counts_alpha(cleaned).size\n",
    "    \n",
    "    @cache\n",
    "    def total_words(self, cleaned=True):\n",
    "        return int(self.word_counts_alpha(cleaned)[\"count\"].sum())\n",
    "    \n",
    "    @cache \n",
    "    def word_frequencies(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class module_TimeSeries:\n",
    "    @cache\n",
    "    def timeseries(self):\n",
    "        dictionary = defaultdict(lambda: [0, None])\n",
    "\n",
    "        for message in self.messages:\n",
    "            for word in message.words:\n",
    "                index = (self.name, message.id, word.word, word.lang, message.time)\n",
    "                dictionary[index][0] += 1\n",
    "                if dictionary[index][1] == None:\n",
    "                    dictionary[index][1] = word.freq\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(dictionary, orient=\"index\", columns=[\"count\", \"freq\"])\n",
    "        df.index = pd.MultiIndex.from_tuples(df.index, names=[\"name\", \"id\", \"word\", \"lang\", \"time\"])\n",
    "        return df.reset_index()\n",
    "    \n",
    "    @cache\n",
    "    def timebins(self, timebin, func=np.sum, exclude=[\"id\"], sort=[\"time\"], timespan = []):\n",
    "        cols = [col for col in [\"name\", \"id\", \"word\", \"lang\", \"freq\"] if col not in exclude]\n",
    "        df = self.timeseries().drop(columns=exclude).groupby([pd.Grouper(key=\"time\", freq=timebin), *cols]).apply(func).reset_index()\n",
    "        df[\"rel_freq\"] = df[\"count\"] / df.groupby(\"time\")[\"count\"].transform(sum)\n",
    "        df[\"overrep\"] = df[\"rel_freq\"] / df[\"freq\"]\n",
    "        return df.sort_valus(by=sort)\n",
    "\n",
    "\n",
    "class AllModules(User, module_WordCounts, module_TimeSeries):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521465db",
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_uploader = widgets.FileUpload(\n",
    "    accept='.json',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "display(telegram_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_uploader = widgets.FileUpload(\n",
    "    accept='.json',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "display(vk_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ace03",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_choice = widgets.ToggleButtons(\n",
    "    options=[\"mine\", \"not mine\"],\n",
    "    description=\"Whose chat to analyze?\",\n",
    "    disabled=False,\n",
    "    tooltips=[\"Your chat\", \"Other person's chat\"],\n",
    ")\n",
    "\n",
    "display(user_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(telegram_uploader, user_class=AllModules)\n",
    "display(chat.me.word_counts_sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(telegram_uploader, user_class=AllModules)\n",
    "\n",
    "if chat.me != None and chat.you != None:\n",
    "    person = chat.me\n",
    "    if user_choice.value != \"mine\":\n",
    "        person = chat.you\n",
    "\n",
    "    display(person.timeseries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chat.me != None and chat.you != None:\n",
    "    tb = person.timebins(\"365D\").sort_values(\"overrep\", ascending=False)\n",
    "    tb.to_csv(\"test.csv\")\n",
    "    display(tb[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if chat.me != None and chat.you != None:\n",
    "    source = pd.concat([chat.me.timeseries().resample('D', on=\"time\").agg({'radiation': np.sum, 'tamb': np.mean}).assign(Name=chat.me.name),\n",
    "                chat.you.timeseries().resample('D', on=\"time\").sum().assign(Name=chat.you.name)]).reset_index()\n",
    "\n",
    "    display(source)\n",
    "\n",
    "    interval = alt.selection_interval(encodings=[\"x\"])\n",
    "    selection = alt.selection_point(fields=['Name'], bind='legend')\n",
    "\n",
    "    chart_base = alt.Chart(source).mark_area().encode(\n",
    "        x=alt.X(\"time:T\").title(\"Date\"),\n",
    "        y=alt.Y(\"count:Q\").title(\"Word Count\"),\n",
    "        color=alt.Color(\"Name:N\"),\n",
    "        opacity=alt.when(selection).then(alt.value(0.75)).otherwise(alt.value(0.2))\n",
    "    ).add_params(selection).transform_filter(selection)\n",
    "\n",
    "    rolling_base = alt.Chart(source).mark_area(color=\"green\", line={\"color\": \"green\", \"opacity\": 0.7}).encode(\n",
    "        x=alt.X('time:T').title(\"Date\"),\n",
    "        y='rolling_mean:Q',\n",
    "        color=alt.Color(\"Name:N\"),\n",
    "        opacity=alt.when(selection).then(alt.value(0.33)).otherwise(alt.value(0.1))\n",
    "    ).transform_window(\n",
    "        rolling_mean='mean(count)',\n",
    "        frame=[-14, 14]\n",
    "    ).add_params(selection).transform_filter(selection)\n",
    "\n",
    "    bases = [chart_base, rolling_base]\n",
    "\n",
    "    chart, rolling_mean = [base.encode(\n",
    "        x=alt.X('time:T', scale=alt.Scale(domain=interval.to_dict())).title(\"Date\")\n",
    "    ).properties(width=1000, height=300) for base in bases]\n",
    "    chart_view, rolling_mean_view = [base.add_params(interval).properties(width=1000, height=50) for base in bases]\n",
    "\n",
    "    (chart_view + rolling_mean_view) & (chart + rolling_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565489c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "class MyCustomRoutine:  # noqa: D101\n",
    "    def __init__(self, mesh):\n",
    "        self.output = mesh  # Expected PyVista mesh type\n",
    "        # default parameters\n",
    "        self.kwargs = {\n",
    "            'center': (0, 0, 0),\n",
    "        }\n",
    "\n",
    "        self.center = {\"x\": 0,\n",
    "                       \"y\": 0,\n",
    "                       \"z\": 0}\n",
    "\n",
    "    def __call__(self, param, value):\n",
    "        if param in [\"x\", \"y\", \"z\"]:\n",
    "            self.center[param] = value\n",
    "            self.kwargs[\"center\"] = tuple(self.center.values())\n",
    "            self.update()\n",
    "        else:\n",
    "            self.kwargs[param] = value\n",
    "            self.update()\n",
    "\n",
    "    def update(self):\n",
    "        # This is where you call your simulation\n",
    "        result = pv.Sphere(**self.kwargs)\n",
    "        self.output.copy_from(result)\n",
    "starting_mesh = pv.Sphere()\n",
    "engine = MyCustomRoutine(starting_mesh)\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(starting_mesh, show_edges=True)\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('x', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='x',\n",
    "    pointa=(0.025, 0.1),\n",
    "    pointb=(0.31, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('y', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='y',\n",
    "    pointa=(0.35, 0.1),\n",
    "    pointb=(0.64, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('z', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='z',\n",
    "    pointa=(0.67, 0.1),\n",
    "    pointb=(0.98, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d079a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
