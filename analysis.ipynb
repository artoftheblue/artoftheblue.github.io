{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4306736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import altair as alt\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wordfreq as wf\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import cache\n",
    "\n",
    "print(\"Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7117f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf9ecf",
   "metadata": {
    "user_expressions": [
     {
      "expression": "a + b",
      "result": {
       "data": {
        "text/plain": "5"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "{eval}`a + b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94474c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word:\n",
    "    def __init__(self, word, _type):\n",
    "        self.word = word\n",
    "        self.type = _type\n",
    "        self.lang = self.eval_lang(self.word)\n",
    "        self.freq = self.eval_freq(self.word, self.lang)\n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_lang(word):\n",
    "        if any(letter in word.lower() for letter in \"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"):\n",
    "            return \"ru\"\n",
    "        return \"en\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_freq(word, language):\n",
    "        return wf.word_frequency(word, language)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.word\n",
    "\n",
    "\n",
    "class Message:\n",
    "    characters_to_remove = r'!@#$%^&*()_+=/?\\|][{}<>;\"~`—–«»'\n",
    "    border_characters = \"'-:\"\n",
    "    replacement_pairs = [\n",
    "        (\"\\\\\", \" \"),\n",
    "        (\"/\", \" \"),\n",
    "        (\"|\", \" \"),\n",
    "        (\".\", \" \"),\n",
    "        (\",\", \" \"),\n",
    "        (\"”\", '\"'),\n",
    "        (\"“\", '\"'),\n",
    "        (\"’\", \"'\"),\n",
    "        (\"‘\", \"'\"),\n",
    "        (\"»\", '\"'),\n",
    "        (\"«\", '\"'),\n",
    "        (\"…\", \"...\")\n",
    "    ]\n",
    "\n",
    "    def __init__(self, id, unixtime, text_entities):\n",
    "        self.id = id\n",
    "        self.time = datetime.datetime.fromtimestamp(int(unixtime))\n",
    "        self.strings = []\n",
    "        self.words = []\n",
    "\n",
    "        self.__process_text(text_entities)\n",
    "    \n",
    "    def __process_text(self, text_entities):\n",
    "        def filtered(string):\n",
    "            string = string.lower()\n",
    "\n",
    "            for pair in Message.replacement_pairs:\n",
    "                string = string.replace(*pair)\n",
    "\n",
    "            for char in Message.characters_to_remove:\n",
    "                string = string.replace(char, '')\n",
    "\n",
    "            return string\n",
    "        \n",
    "        def filtered2(string):\n",
    "            while any(string.startswith(char) for char in Message.border_characters):\n",
    "                string = string[1:]\n",
    "\n",
    "            while any(string.endswith(char) for char in Message.border_characters):\n",
    "                string = string[:-1]\n",
    "            \n",
    "            return string\n",
    "        \n",
    "        for entity in text_entities:\n",
    "            for string in entity[\"text\"].split():\n",
    "                self.strings.append(Word(string, entity[\"type\"]))\n",
    "            \n",
    "            for word in filtered(entity[\"text\"]).split():\n",
    "                word = filtered2(word)\n",
    "\n",
    "                if word == \"\":\n",
    "                    continue\n",
    "\n",
    "                self.words.append(Word(word, entity[\"type\"]))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"[{self.time}] {' '.join(self.strings)}\\n{' '.join(self.words)}\"\n",
    "\n",
    "\n",
    "class Call:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class User:\n",
    "    def __init__(self, id, name):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.messages = []\n",
    "        self.calls = []\n",
    "    \n",
    "    def _add_message(self, json_object):\n",
    "        if \"text_entities\" not in json_object:\n",
    "            json_object[\"text_entities\"] = self.to_json(json_object[\"text\"])\n",
    "        \n",
    "        self.messages.append(Message(json_object[\"id\"], json_object[\"date_unixtime\"], json_object[\"text_entities\"]))\n",
    "    \n",
    "    def _add_call(self, json_object):\n",
    "        self.calls = Call()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_json(string):\n",
    "        return [{\"text\": string, \"type\": \"plain\"}]\n",
    "\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self, *uploaders, user_class=User):\n",
    "        self.id = None\n",
    "        self.me = None\n",
    "        self.you = None\n",
    "\n",
    "        for uploader in uploaders:\n",
    "            if len(uploader.value) != 0:\n",
    "                data = self.__load_data(uploader)\n",
    "                self.__process_messages(user_class, data)\n",
    "\n",
    "    def __load_data(self, uploader):\n",
    "        raw_data = json.loads(uploader.value[list(uploader.value.keys())[0]][\"content\"])\n",
    "        #raw_data = json.loads(uploader.value[0].content.tobytes())\n",
    "\n",
    "        if \"type\" in raw_data and raw_data[\"type\"] != \"personal_chat\":\n",
    "            raise FileNotFoundError(\"File uploaded is not from a personal_chat\")\n",
    "        \n",
    "        if self.id == None:\n",
    "            self.id = str(raw_data[\"id\"])\n",
    "\n",
    "        return raw_data\n",
    "    \n",
    "    def __process_messages(self, user_class, raw_data):\n",
    "        def user(id):\n",
    "            if id.endswith(self.id):\n",
    "                return self.you\n",
    "            return self.me\n",
    "        \n",
    "        if raw_data == None:\n",
    "            raise FileNotFoundError(\"No data loaded\")\n",
    "\n",
    "        for json_object in raw_data[\"messages\"]:\n",
    "            if \"type\" not in json_object or json_object[\"type\"] == \"message\":\n",
    "                id = json_object[\"from_id\"]\n",
    "\n",
    "                if self.me == None or self.you == None:\n",
    "                    if id.endswith(self.id):\n",
    "                        self.you = user_class(self.id, json_object[\"from\"])\n",
    "                    else:\n",
    "                        self.me = user_class(id[4:], json_object[\"from\"])\n",
    "                \n",
    "                user(id)._add_message(json_object)\n",
    "            elif json_object[\"type\"] == \"service\":\n",
    "                pass\n",
    "            else:\n",
    "                print(\"[WARNING] unknown object found\")\n",
    "                display(json_object)\n",
    "\n",
    "\n",
    "class module_WordCounts:\n",
    "    @cache\n",
    "    def __word_counts(self, attribute):        \n",
    "        dictionary = defaultdict(lambda: [0])\n",
    "\n",
    "        for message in self.messages:\n",
    "            for word in getattr(message, attribute): \n",
    "                dictionary[word.word][0] += 1\n",
    "\n",
    "        df = pd.DataFrame(dictionary).transpose().reset_index()\n",
    "        df.columns = [\"word\", \"count\"]\n",
    "        return df\n",
    "\n",
    "    @cache\n",
    "    def word_counts_sorted(self, cleaned=True):\n",
    "        return self.word_counts_alpha(cleaned).sort_values(\"count\", ascending=False)\n",
    "\n",
    "    @cache\n",
    "    def word_counts_alpha(self, cleaned=True):\n",
    "        attribute = \"words\" \n",
    "        if not cleaned:\n",
    "            attribute = \"strings\"\n",
    "            \n",
    "        return self.__word_counts(attribute).sort_index()\n",
    "    \n",
    "    @cache\n",
    "    def unique_words(self, cleaned=True):\n",
    "        return self.word_counts_alpha(cleaned).size\n",
    "    \n",
    "    @cache\n",
    "    def total_words(self, cleaned=True):\n",
    "        return int(self.word_counts_alpha(cleaned)[\"count\"].sum())\n",
    "    \n",
    "    @cache \n",
    "    def word_frequencies(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class module_TimeSeries:\n",
    "    @cache\n",
    "    def timeseries(self):\n",
    "        dictionary = defaultdict(lambda: [0, None])\n",
    "\n",
    "        for message in self.messages:\n",
    "            for word in message.words:\n",
    "                index = (self.name, message.id, word.word, word.lang, message.time)\n",
    "                dictionary[index][0] += 1\n",
    "                if dictionary[index][1] == None:\n",
    "                    dictionary[index][1] = word.freq\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(dictionary, orient=\"index\", columns=[\"count\", \"freq\"])\n",
    "        df.index = pd.MultiIndex.from_tuples(df.index, names=[\"name\", \"id\", \"word\", \"lang\", \"time\"])\n",
    "        return df.reset_index()\n",
    "    \n",
    "    @cache\n",
    "    def timebins(self, timebin, func=np.sum, exclude=[\"id\"]):\n",
    "        cols = [col for col in [\"name\", \"id\", \"word\", \"lang\", \"freq\"] if col not in exclude]\n",
    "        df = self.timeseries().drop(columns=exclude).groupby([pd.Grouper(key=\"time\", freq=timebin), *cols]).apply(func).reset_index()\n",
    "        df[\"rel_freq\"] = df[\"count\"] / df.groupby(\"time\")[\"count\"].transform(sum)\n",
    "        df[\"overrep\"] = df[\"rel_freq\"] / df[\"freq\"]\n",
    "        return df\n",
    "\n",
    "\n",
    "class AllModules(User, module_WordCounts, module_TimeSeries):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521465db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d324126c71aa4d29b4b25997aeb2ba5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.json', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "telegram_uploader = widgets.FileUpload(\n",
    "    accept='.json',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "display(telegram_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd8dbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0b3ab7cf5493d84d1af64060980c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.json', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vk_uploader = widgets.FileUpload(\n",
    "    accept='.json',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "display(vk_uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26ace03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac85fd1f20904ae3834640810bd1642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Whose chat to analyze?', options=('mine', 'not mine'), tooltips=('Your chat', \"Othe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_choice = widgets.ToggleButtons(\n",
    "    options=[\"mine\", \"not mine\"],\n",
    "    description=\"Whose chat to analyze?\",\n",
    "    disabled=False,\n",
    "    tooltips=[\"Your chat\", \"Other person's chat\"],\n",
    ")\n",
    "\n",
    "display(user_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65f4876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>29548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>the</td>\n",
       "      <td>20683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>19675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>and</td>\n",
       "      <td>14087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29098</th>\n",
       "      <td>линал-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29100</th>\n",
       "      <td>густо</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29101</th>\n",
       "      <td>фэновскими</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29102</th>\n",
       "      <td>предметами</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56250</th>\n",
       "      <td>ehewhehaehhe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  count\n",
       "0                 i  29548\n",
       "68              the  20683\n",
       "9                to  19675\n",
       "2               you  16819\n",
       "82              and  14087\n",
       "...             ...    ...\n",
       "29098       линал-2      1\n",
       "29100         густо      1\n",
       "29101    фэновскими      1\n",
       "29102    предметами      1\n",
       "56250  ehewhehaehhe      1\n",
       "\n",
       "[56251 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(telegram_uploader, vk_uploader, user_class=AllModules)\n",
    "display(chat.me.word_counts_sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a398b846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>lang</th>\n",
       "      <th>time</th>\n",
       "      <th>count</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>44240</td>\n",
       "      <td>awhhwh</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-10-03 23:11:54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>44240</td>\n",
       "      <td>you</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-10-03 23:11:54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>44240</td>\n",
       "      <td>are</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-10-03 23:11:54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>44240</td>\n",
       "      <td>the</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-10-03 23:11:54</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>44240</td>\n",
       "      <td>best</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-10-03 23:11:54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304938</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1366228</td>\n",
       "      <td>i'm</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-12-25 23:42:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304939</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1366228</td>\n",
       "      <td>going</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-12-25 23:42:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304940</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1366228</td>\n",
       "      <td>to</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-12-25 23:42:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304941</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1366228</td>\n",
       "      <td>sleep</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-12-25 23:42:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304942</th>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1366228</td>\n",
       "      <td>c</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-12-25 23:42:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1304943 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name       id    word lang                time  count  \\\n",
       "0        Katya Feidenheimer    44240  awhhwh   en 2021-10-03 23:11:54      1   \n",
       "1        Katya Feidenheimer    44240     you   en 2021-10-03 23:11:54      1   \n",
       "2        Katya Feidenheimer    44240     are   en 2021-10-03 23:11:54      1   \n",
       "3        Katya Feidenheimer    44240     the   en 2021-10-03 23:11:54      2   \n",
       "4        Katya Feidenheimer    44240    best   en 2021-10-03 23:11:54      1   \n",
       "...                     ...      ...     ...  ...                 ...    ...   \n",
       "1304938  Katya Feidenheimer  1366228     i'm   en 2022-12-25 23:42:20      1   \n",
       "1304939  Katya Feidenheimer  1366228   going   en 2022-12-25 23:42:20      1   \n",
       "1304940  Katya Feidenheimer  1366228      to   en 2022-12-25 23:42:20      1   \n",
       "1304941  Katya Feidenheimer  1366228   sleep   en 2022-12-25 23:42:20      1   \n",
       "1304942  Katya Feidenheimer  1366228       c   en 2022-12-25 23:42:20      1   \n",
       "\n",
       "             freq  \n",
       "0        0.000000  \n",
       "1        0.009550  \n",
       "2        0.005500  \n",
       "3        0.053700  \n",
       "4        0.000692  \n",
       "...           ...  \n",
       "1304938  0.001410  \n",
       "1304939  0.000871  \n",
       "1304940  0.026900  \n",
       "1304941  0.000112  \n",
       "1304942  0.000214  \n",
       "\n",
       "[1304943 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if chat.me != None and chat.you != None:\n",
    "    person = chat.me\n",
    "    if user_choice.value != \"mine\":\n",
    "        person = chat.you\n",
    "\n",
    "    display(person.timeseries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c670cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "c:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "C:\\Users\\artemis\\AppData\\Local\\Temp\\ipykernel_7592\\1559425683.py:220: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df[\"rel_freq\"] = df[\"count\"] / df.groupby(\"time\")[\"count\"].transform(sum)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>name</th>\n",
       "      <th>word</th>\n",
       "      <th>lang</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>rel_freq</th>\n",
       "      <th>overrep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100286</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>7237704611736407342</td>\n",
       "      <td>en</td>\n",
       "      <td>1.720000e-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.435072e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100285</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>7112482605475384622</td>\n",
       "      <td>en</td>\n",
       "      <td>1.720000e-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.435072e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63171</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1596186359689089031</td>\n",
       "      <td>en</td>\n",
       "      <td>9.060000e-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.741319e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63172</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1599070922379784192</td>\n",
       "      <td>en</td>\n",
       "      <td>9.060000e-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.741319e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63170</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>1595349342289805316</td>\n",
       "      <td>en</td>\n",
       "      <td>9.060000e-27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.741319e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62715</th>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>я...</td>\n",
       "      <td>ru</td>\n",
       "      <td>8.130000e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.284684e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652</th>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>of...</td>\n",
       "      <td>en</td>\n",
       "      <td>2.510000e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.334650e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80541</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>и...</td>\n",
       "      <td>ru</td>\n",
       "      <td>2.950000e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.149029e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99548</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>‎в</td>\n",
       "      <td>ru</td>\n",
       "      <td>4.270000e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.938256e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41530</th>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>Katya Feidenheimer</td>\n",
       "      <td>to¿</td>\n",
       "      <td>en</td>\n",
       "      <td>2.690000e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.905012e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128817 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time                name                 word lang          freq  \\\n",
       "100286 2023-11-21  Katya Feidenheimer  7237704611736407342   en  1.720000e-27   \n",
       "100285 2023-11-21  Katya Feidenheimer  7112482605475384622   en  1.720000e-27   \n",
       "63171  2022-11-21  Katya Feidenheimer  1596186359689089031   en  9.060000e-27   \n",
       "63172  2022-11-21  Katya Feidenheimer  1599070922379784192   en  9.060000e-27   \n",
       "63170  2022-11-21  Katya Feidenheimer  1595349342289805316   en  9.060000e-27   \n",
       "...           ...                 ...                  ...  ...           ...   \n",
       "62715  2021-11-21  Katya Feidenheimer                 я...   ru  8.130000e-03   \n",
       "9652   2020-11-21  Katya Feidenheimer                of...   en  2.510000e-02   \n",
       "80541  2022-11-21  Katya Feidenheimer                 и...   ru  2.950000e-02   \n",
       "99548  2022-11-21  Katya Feidenheimer                   ‎в   ru  4.270000e-02   \n",
       "41530  2021-11-21  Katya Feidenheimer                  to¿   en  2.690000e-02   \n",
       "\n",
       "        count  rel_freq       overrep  \n",
       "100286      1  0.000004  2.435072e+21  \n",
       "100285      1  0.000004  2.435072e+21  \n",
       "63171       1  0.000003  3.741319e+20  \n",
       "63172       1  0.000003  3.741319e+20  \n",
       "63170       1  0.000003  3.741319e+20  \n",
       "...       ...       ...           ...  \n",
       "62715       1  0.000002  2.284684e-04  \n",
       "9652        1  0.000003  1.334650e-04  \n",
       "80541       1  0.000003  1.149029e-04  \n",
       "99548       1  0.000003  7.938256e-05  \n",
       "41530       1  0.000002  6.905012e-05  \n",
       "\n",
       "[128817 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if chat.me != None and chat.you != None:\n",
    "    tb = person.timebins(\"365D\")\n",
    "    tb= tb[tb[\"overrep\"] != np.inf].sort_values(\"overrep\", ascending=False)\n",
    "    display(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ff9fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b4ff58",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['radiation', 'tamb'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mme \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m chat\u001b[38;5;241m.\u001b[39myou \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     source \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeseries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mradiation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtamb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39massign(Name\u001b[38;5;241m=\u001b[39mchat\u001b[38;5;241m.\u001b[39mme\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m      3\u001b[0m                 chat\u001b[38;5;241m.\u001b[39myou\u001b[38;5;241m.\u001b[39mtimeseries()\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39massign(Name\u001b[38;5;241m=\u001b[39mchat\u001b[38;5;241m.\u001b[39myou\u001b[38;5;241m.\u001b[39mname)])\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      5\u001b[0m     display(source)\n\u001b[0;32m      7\u001b[0m     interval \u001b[38;5;241m=\u001b[39m alt\u001b[38;5;241m.\u001b[39mselection_interval(encodings\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\resample.py:352\u001b[0m, in \u001b[0;36mResampler.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m    345\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 352\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mResamplerWindowApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m         how \u001b[38;5;241m=\u001b[39m func\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1608\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1606\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1607\u001b[0m ):\n\u001b[1;32m-> 1608\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1611\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:462\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m is_groupby \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[0;32m    461\u001b[0m func \u001b[38;5;241m=\u001b[39m cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m--> 462\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m is_non_unique_col \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    465\u001b[0m     selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_obj\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    467\u001b[0m )\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\artemis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:663\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    661\u001b[0m     cols \u001b[38;5;241m=\u001b[39m Index(\u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdifference(obj\u001b[38;5;241m.\u001b[39mcolumns, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    665\u001b[0m aggregator_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['radiation', 'tamb'] do not exist\""
     ]
    }
   ],
   "source": [
    "if chat.me != None and chat.you != None:\n",
    "    source = pd.concat([chat.me.timeseries().resample('D', on=\"time\").agg({'radiation': np.sum, 'tamb': np.mean}).assign(Name=chat.me.name),\n",
    "                chat.you.timeseries().resample('D', on=\"time\").sum().assign(Name=chat.you.name)]).reset_index()\n",
    "\n",
    "    display(source)\n",
    "\n",
    "    interval = alt.selection_interval(encodings=[\"x\"])\n",
    "    selection = alt.selection_point(fields=['Name'], bind='legend')\n",
    "\n",
    "    chart_base = alt.Chart(source).mark_area().encode(\n",
    "        x=alt.X(\"time:T\").title(\"Date\"),\n",
    "        y=alt.Y(\"count:Q\").title(\"Word Count\"),\n",
    "        color=alt.Color(\"Name:N\"),\n",
    "        opacity=alt.when(selection).then(alt.value(0.75)).otherwise(alt.value(0.2))\n",
    "    ).add_params(selection).transform_filter(selection)\n",
    "\n",
    "    rolling_base = alt.Chart(source).mark_area(color=\"green\", line={\"color\": \"green\", \"opacity\": 0.7}).encode(\n",
    "        x=alt.X('time:T').title(\"Date\"),\n",
    "        y='rolling_mean:Q',\n",
    "        color=alt.Color(\"Name:N\"),\n",
    "        opacity=alt.when(selection).then(alt.value(0.33)).otherwise(alt.value(0.1))\n",
    "    ).transform_window(\n",
    "        rolling_mean='mean(count)',\n",
    "        frame=[-14, 14]\n",
    "    ).add_params(selection).transform_filter(selection)\n",
    "\n",
    "    bases = [chart_base, rolling_base]\n",
    "\n",
    "    chart, rolling_mean = [base.encode(\n",
    "        x=alt.X('time:T', scale=alt.Scale(domain=interval.to_dict())).title(\"Date\")\n",
    "    ).properties(width=1000, height=300) for base in bases]\n",
    "    chart_view, rolling_mean_view = [base.add_params(interval).properties(width=1000, height=50) for base in bases]\n",
    "\n",
    "    (chart_view + rolling_mean_view) & (chart + rolling_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565489c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "class MyCustomRoutine:  # noqa: D101\n",
    "    def __init__(self, mesh):\n",
    "        self.output = mesh  # Expected PyVista mesh type\n",
    "        # default parameters\n",
    "        self.kwargs = {\n",
    "            'center': (0, 0, 0),\n",
    "        }\n",
    "\n",
    "        self.center = {\"x\": 0,\n",
    "                       \"y\": 0,\n",
    "                       \"z\": 0}\n",
    "\n",
    "    def __call__(self, param, value):\n",
    "        if param in [\"x\", \"y\", \"z\"]:\n",
    "            self.center[param] = value\n",
    "            self.kwargs[\"center\"] = tuple(self.center.values())\n",
    "            self.update()\n",
    "        else:\n",
    "            self.kwargs[param] = value\n",
    "            self.update()\n",
    "\n",
    "    def update(self):\n",
    "        # This is where you call your simulation\n",
    "        result = pv.Sphere(**self.kwargs)\n",
    "        self.output.copy_from(result)\n",
    "starting_mesh = pv.Sphere()\n",
    "engine = MyCustomRoutine(starting_mesh)\n",
    "p = pv.Plotter()\n",
    "p.add_mesh(starting_mesh, show_edges=True)\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('x', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='x',\n",
    "    pointa=(0.025, 0.1),\n",
    "    pointb=(0.31, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('y', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='y',\n",
    "    pointa=(0.35, 0.1),\n",
    "    pointb=(0.64, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.add_slider_widget(\n",
    "    callback=lambda value: engine('z', float(value)),\n",
    "    rng=[-5, 5],\n",
    "    value=0,\n",
    "    title='z',\n",
    "    pointa=(0.67, 0.1),\n",
    "    pointb=(0.98, 0.1),\n",
    "    style='modern',\n",
    "    interaction_event='always'\n",
    ")\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d079a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
